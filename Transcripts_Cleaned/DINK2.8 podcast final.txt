In this podcast, we will unfold some of the perspectives and dilemmas associated with scaling of digital solutions. The podcast is designed as a complementary component to the videos in the module, and its intended use is slightly different. Our intention is not to have you scribbling notes while listening, but instead, we invite you to immerse yourself in the many discussions of this podcast while working out, or perhaps cleaning house, allowing you to contemplate and reflect on various concepts at your own pace. Throughout this podcast, you'll be introduced to the following discussions. Security and user experience are the two opposites. Delving into the dynamic relationship between security and user experience, are they truly contradictory, or can they coexist harmoniously? Data and security explore the intersection of data utilization and security considerations. How can we harness the power of data without compromising vital security measures? Managing complexity and users uncover strategies for managing complexity while keeping user needs at the forefront, balancing intricate systems with user-friendly experiences. Designing a system that users can trust. We uncover the principles of designing trustworthy systems. What factors contribute to user trust, and how can these principles be applied? Can you scale in a sustainable way? Can you scale your innovations in a sustainable manner? We'll explore the intricacies of growth and sustainability in the digital landscape. Preparing for rapid scaling or not. Is rapid scaling always on the horizon? Delve into the considerations and strategies that come into play when preparing for or reacting to sudden growth. Hardware's role in scaling. Is hardware a limiting factor in the quest for scalability? We'll dissect the relationship between software innovation and hardware constraints. Learning from data while minding ethics. As we harness the power of data, we must also navigate the ethical landscape. Explore the nuances of responsible data utilization and the importance of ethics. You can choose to snack-size this podcast and listen to one topic at a time, or just listen to it in its full length. Enjoy. So, welcome to this podcast. Today we are going to unfold some of the dilemmas and discussions around innovation and security and safety and scalability and issues that sometimes pop up. But we're not always conscious about that in the early phases of innovation. And I'm really happy today to welcome Tim McAloon, Liene Clemmensen, Christian Damsgaard and Paul Popp. And I will let you introduce yourself briefly to your background. So Tim first. Yes, hello. My name is Tim McAloon and I'm a professor of sustainable product service systems at DTU Construct. And what that actually means, my main focus is sustainability, but a means to that is the so-called product service systems or alternative ways of providing value than just products and product development. And that, of course, includes things like digital solutions. I think that's why I'm here today. It is. Thank you. Welcome. Liene. Yes. Hi. I'm an associate professor at DTU Compute in machine learning and data-driven innovation. And so most of my research is in the machine learning methodology, but also how we can actually use data and the right data when we are building those digital models. And what are we building for? Is it a population-wise or individual target? Welcome to you as well. Thank you. Christian. Yeah. Hello. My name is Christian Damsgaard-Jensen. I'm an associate professor in the cybersecurity engineering section where I work on cybersecurity, interestingly enough. So, yeah. Welcome to you. And Paul. And yeah, I'm Paul Popp. I'm a professor of cyber-physical systems, but I'm actually a computer scientist. I design algorithms and software that help you analyze and optimize real-time applications that are distributed across the computing continuum from cloud to edge to IoT devices. And here, networking also plays an important role. So welcome to you also, Paul. And I can maybe say that my name is Pierre Beckor. I'm also an associate professor here at DTU Compute. And I'm working on user experience as one of the parts here, and also how this applies to innovation. Sometimes, at least when I've been in large companies, we have divided the functions. So there's somebody who's taking care of the product management side and the user's experience. Others are taking care of the backend and the designs, and somebody is then taking care of the security and so on. So we end up with a little bit of polarized world, perhaps. And sometimes we also see security as sort of the enemy of the user experience in the sense that things become more complex and more sort of difficult to work with. Is it really like that? Or what is your perspective on security when you design things? I think it is, in some respects, correct that in order to authenticate people and find out who we are actually interacting with, then things become a little bit more cumbersome. But also, it's often because we haven't designed systems for people or for ordinary people. We very often design our systems for engineers to use, because we are engineers ourselves. And therefore, it can be difficult for people to understand the security abstractions and the abstractions of the applications and how to interact with it in a secure way. And sometimes it's not even really possible. So one example that I often give is the message that we often give people is not to click on links that you receive in an email. And then most organizations have some kind of workflow system to manage their finances, which means that very often they distribute emails. And then you can click and authorize a payment in that workflow system through your email. So essentially, we're telling people, do not click on links in emails, except the links in emails that you have to click on, which is not a simple message for ordinary people to understand. Then we can simplify that by saying, OK, but typically, malicious people are from the outside. That's at least the way we like to see things. So don't click on links in emails coming from the outside. And then three months later, we have an employee satisfaction survey where we have an external company providing us with a survey that we have to click on and access. And so it becomes very confusing for people to relate to this. So the security hasn't been thought in a methodical way from the beginning of the system. And therefore, we are fighting our abstractions as we're going along with the system going forward. So I mean, security obviously has a benefit for the company that wants to protect some data. But isn't there an issue also, for me as an individual, that I don't do anything stupid, at least I'm not supposed to do that. So what's the added value for the individual in the organization? So I think both in the organization and the organization's users or customers, I think security has a very important role to play. And for the customers, it is, do you want to engage with an organization that has a track record of not protecting your data or is abusing it in all sorts of nasty ways? And of course, you don't really want to interact with these companies, which means that if you don't have a sufficiently good security, then you might not have customers at all. So that's kind of like the customer perspective. For the employees, I think if you're working on a product, it's not so much your own. I mean, of course, your employee records and things in HR is something that you'd like to have protected. And also, of course, the crown jewels of the company, all the intellectual property or whatever it is that you're sitting on, it's important to protect because otherwise the company will not be there tomorrow. But apart from that, I think the individual employee is probably only concerned with security insofar as they live with it. So they have to authenticate themselves, multi-factor authentication, have a device and all the things that the hoops that we are asked to jump through. And then, of course, they have to implement it in their products. So they need to understand it, at least to some degree, that they're not doing something stupid. And then, of course, for the companies, they want customers, so they need to be seen to be secure. They probably don't want to have some of these fines that are going to be introduced with the EU regulations that are both in place and on track. So also, therefore, they want to improve their security. And then finally, of course, I think there are business leaders who just want to be good people and therefore they want to be secure and secure the data of the people that they are recording in some way. So, Christian, you talked about value also here. Tim, from a more business perspective, do customers typically understand the value of security, especially when they need to deal with a little bit more cumbersome?
product and a double login, something multi-factor authentication thingy? I guess so. So I think there's different types of ways of creating or transferring value from a company to a user or a customer. And we typically work with three main modes, there's the sort of results and performance-based value creation, which is where the customer is less involved with the interaction of a product or with the data themselves. I guess the security issues there are less front of mind for the user or the customer. Then we have access and availability-based value creation or business models. That could be, for example, your ShareNow or your Scusa in the tower. Depending on how often you use it and depending on the type and level of interaction, I think there's some security issues there that you may think about. But I think when the interface comes onto your mobile phone, as soon as you got past that phase, I guess once you've authenticated yourself, once somehow been approved to be part of the club of a ShareNow system or whatever, then I'm guessing that the security mindset is less front of mind. The third type of alternative way of creating and transferring value from a company that we often categorize as these so-called product longevity type services, so services where we try and keep a product on the market for as long as possible through remote maintenance. These are often business-to-business types of services. Then I know that security is a big concern because all of a sudden we're operating a crane for a company in a mine and we'd like that crane to function, but we'd also like it not to malfunction. And I know that the security issues there and the security concerns have raised over recent years. Windows more maintenance of its product life warranted services, which are being the data which is transferred back and forth then. So I'd probably say there's different graduations of concern. Data and security. So we kind of become accustomed to sharing a lot of our behavioral things with companies. That's what recommender systems are based on and you touched on that, even the car sharing system can actually reveal very highly sensitive information about us as individuals. So of course, we're just not thinking about that very often. We just share it freely and that's value, of course, for the company. It could also be value, but it could also be a tremendous disaster for the company or for the individual. But that's part of the value creation and that's the data thing, Lene. I mean, this is the value that might be inside of data, which could be the personalized ads that you're saying. It could be, how am I using my phone? Do I remember to charge it every night, etc. Then I'm a responsible person, so I might grant you a loan based on your phone usage or just the behavior you have. It could be the variables and again, the behavior we have there and we can sort of then notch people to a healthier lifestyle. So there are many possibilities, right? How can we use those data in order to bring value? And that could be depending on the company you are, what do you think of as value, right? Yeah. So what we do and how we interact actually creates value, but it can be, as you say, highly sensitive value. I mean, some of what you said about sleeping patterns or other things can be maybe something you don't want to share with everyone. So having this security mindset or understanding that there are perspectives of that is important. If I look at some of the things that are maybe sometimes happening outside in the big world, it's also about data leakage or things that are sort of disappearing. You mentioned the example, Tim, of older systems that go into maintenance mode. And I mean, even though you talk about the service by design, maybe that things have to be designed from the start, what about the end? I mean, there are a number of ways of talking about the end of a computer system or an application because, I mean, we're seeing things just being discontinued and then you're stuck. Hopefully data that belongs to that application will be deleted after that point, except that there are probably legislation saying something about whether data should be retained for a certain period of time. I believe that you would probably also argue that you would need to keep it for a certain period of time so that people, according to the GDPR, could claim to get their data out and use it in another application that they might want to switch to later on. And then once you have that kind of application perspective and the data from the applications perspective, then there is what you actually do with the physical hardware. And I think that most companies these days are conscious about wiping hard disks, hard drives properly when they decommission their computers or reinstall them for other purposes. But in the past, there have been some nasty cases where they basically just shipped off their computers to schools in a less developed country or something like that. And then application data was available for school students in other countries. And there might also be possibilities of innovation saying, okay, you can keep your data on your phone. I'm just going to send an algorithm that computes the value right there distributed. So there are lots of innovation possibilities in thinking security and data protection into the systems in a different way. Yeah. So it could also be done in more clever ways, perhaps. So we don't necessarily need to store all that kind of data on cloud computers or whatever. So that's one of the things that are, at least from a security perspective, quite interesting in some of the development in artificial intelligence at the moment, this whole idea about federated learning, where we actually keep our data decentralized, but then we distribute the algorithms as that. So function shipping rather than data shipping. So federated computing. Federated learning. So it seems like, based on what you're saying, that as systems are being used, we also build up more and more value, sort of non-tangible assets maybe, but the data that we have, that even if the business itself might end, or the original business idea might terminate, then there could still be value also in bringing that on to something else. And that kind of brings us to this perspective of where the data is stored. And you said, Christian, that most responsible companies, they decommission data in a good way. But then we move to the cloud. Yeah. The data can sit in a cloud and not on the hard disk that you wipe. And we often say that data and software are immaterial. They are bits, ones and zeros, sitting somewhere on a hard disk, traveling on a wire, being executed in a CPU somewhere. And because it's immaterial, you can see it as virtual. You can see that the data and software are virtualized representations. And as a developer, if you want to develop applications, nowadays it's relatively easy to get access to very large virtual machines in a cloud or data centers and just start your services there. And you, as a startup, as a company, you can just pay for the usage of those resources. And this allows you to scale applications a lot. And there are challenges related to this. How do you rethink your programming models and the data representation to reside in the cloud? You have to program things differently, probably as microservices, if you want to run them in the cloud. You have to think about where your data is located and how quickly you can access it. Because depending on how much data you need to access, it may be residing on different computers, different hard disks. And actually, it takes a while to gather it together and work on it. And as engineers, we are often falling in love with some technologies. And when people develop new solutions, they often want to emulate companies, I don't know, like Google and Netflix. Let's all use Kubernetes to scale things up. But that's just too much complexity. When you start up with some ideas, it's better to just have a simple product to judge product market fit and have a very simple solution that is not necessarily extremely scalable. But be worried about getting a lot of users later. Initially, be worried less about the scalability and more about your product market fit, about the business value of what you do. But of course, you may be lucky and you may be getting a lot of users. And then you run into different problems. We just said that you can have a pay-as-you-go model with the cloud, but it does not come cheap. Sometimes those costs can balloon. And you also have to be aware of how you use cloud resources. And a lot of times, data does not reside only on your local hard disk and in the cloud. It can be anywhere in the network. There may be applications where you need real-time response, thinking about video or maybe some real-time video, for example. Or maybe you want to process data locally and not in the cloud for all sorts of reasons, maybe speed or privacy reasons. Again, we're talking about cloud.
coming closer to the edge of the network and then we call it not cloud computing but edge computing and then data can be anywhere in this it's called computing continuum from your phone or IOT device to an edge computing server for example or data center somewhere traveling in the network in a cloud data center so and depending on the type of application that you develop you have to be aware that yeah what's the best solution for for what you want to deliver managing complexity and users so I mean in the clouds you might have sort of centralized user management I guess but but when it comes to sort of these very distributed systems where beta can be almost anywhere is it then more difficult question do you think in terms of managing the the complexity of users I mean often when we do a minimum viable product we might not even want people to sign in initially until they start using it for a while so what what is your perspective on that I mean is it is it possible to design it in already from the start or should you just accept that well you know we care about that later that's a really good question because I mean managing identities in a very large scale if you cannot bring them on to one common platform which would be what what you would do if you have managed your your own user database somewhere but you want to run it this more decentralized model and also if you want to have like an increasing number of government say well we actually need to have age verification of people logging into our system so or to your systems then you need to link those identities that people create in your application with real-world identities so they can verify their age at least something else on the outside world that that can attest to their age which means now that you need to to relate to to the different identity schemes in different countries which makes kind of like global scalability a bit of a challenge because they are very very different around the world and the legal constraints on what you have there is very very different around the world so the complexity of the the overall kind of identity management problem is exploding if you want to go global. How to design a system that users can trust? So that kind of I mean brings up another topic perhaps that that I thought about in this context which is trust and of course as individual users we need to trust the systems but but if you start relying on other companies that are providing maybe even service identities Google or the large players that you can always sign in with Google or Facebook or whatever how do you mean from a from a design perspective when you when you're trying to figure out how to set up your platforms I mean do you need to trust your cloud computing provider I can just go with the cheapest one and then because it's it's all in the container so we don't really care or how do you see that? It's a big deal I don't have a lot of experience but when you develop you have to rely on libraries you have to rely on other providers there are many attacks that can happen because maybe somebody has tampered with some open source libraries or some repositories where you you get your packages to manage your docker containers and so on so that's definitely something you should be aware of and you should have used best practices that minimize the risk of tampering with your development pipeline. So if I was a startup and said okay I need to get going here I'll find a solution I think I've designed my system that I need some cloud services and so on and I come to you and ask for best practices from a perspective of designing the system I mean making making your decisions and where to put things I mean... Yeah definitely security is an important perspective but I'm not I'm not considering that you know as researchers you often look at your own little topic and whenever I am thinking about designing something that scales I don't consider security but what I do consider is the security impact on safety because we often think of these two things separately but security may impair safety I work a lot with safety critical systems for example think about medical devices think about an insulin pump or any kind of pump delivering some intravenous for example liquids in a hospital they have to be safe and you have to certify them for for safety of course but any security breach can actually impair the safety and there is a tension between safety and security with security you want to patch as often as possible a new patch would maybe close some security gaps but with safety whenever you change the functionality through a patch or an upgrade you're actually introducing safety risks and you often cannot dispatch because you need to recertify so these are it's a tension between safety and security. So in terms of this trust discussion that we had also now you brought in also the safety from a data collection perspective also and from sort of the machine learning perspective of getting started with something how do you see this I mean I guess we agree that it's important to trust the services that you build or to make sure that your customers will trust those right? So I think from a machine learning perspective is also really important that they are fair and are not discriminating and these are kind of the things that we would need to verify and check and they're very much it's also related again back to data what kind of data do we collect if we haven't seen any kind of training samples that reflect specific groups of our population then our system will not work for those groups of the population and they may even become very discriminative. So for you I mean trust is also about making sure that you design for fairness and having representative data and what you actually collect. And ethical use right so what do we want to use it for is this does it bring value and does it bring value in in a sense maybe it's a very targeted population but if that somehow can bring a dissatisfaction or some kind of stir for other parts of the population this is something we might think of also right to just consider what what are we actually doing sometimes yeah this can be difficult because you're very focused in the beginning you need to produce your MVP and be very targeted on your users and you should be to make a good product and bring that value to market and then what about the rest right. So if I would ask you also about good advice for my startup idea my innovation idea in terms of the data then I mean what what would be some of the keywords I mean you already mentioned this trust and fairness and in terms of the relationship you have with the users and what you collect. And in collecting the data it would be covering use cases covering your population right so instead of just thinking of collect as much data as possible convenience sample you would need to think very carefully about cover covering that population and the way you sample it's really important. So maybe design your initial systems for collecting the data that you actually want to create the value on and not just any kind of random stuff. Yes. Can you scale in a sustainable way? Tim from a kind of also I mean one of your perspectives is also the sustainability of things and of course that comes with different aspects here but could you just maybe unfold a little bit about that I mean I hear the word cloud computing I'm thinking about you know lots of computers that are standing somewhere in a basement and are generating an enormous amount of heat and just dissipating that into the air and it doesn't sound super sustainable from my perspective. Yeah and there's many studies about this and I don't have the the numbers and the data to. I do it's 2.5% of the global emissions are generated by ICT. It's on par with air travel. Exactly. We're all you know the flick scam or how is it or all flight shamed and not to take the airplane but everybody's using chat GPT which is a ten times more energy consuming than a regular Google search and then and then how can we reduce the energy consumption of and I'm reading somewhere that the Chinese who are now deploying a lot of 5g they turn it off at night because it consumes enormous amounts of power I'm not an expert on that but it's also the communication not only the computation. Right so I think it's the we've created an iceberg of overhead that is really difficult to pinpoint on one particular intervention or one value exchange because we have so much data out there and so much data ready for us to be able to use and what I didn't have the data on but I was gonna that it actually exists is some estimates of about what is the eco footprint as we call it the environmental footprint of a one tune on the CD versus one tune on Spotify or any other service like Spotify for example and intuitively we think it's better to have to not own the physical product right but how many copies of one song a particular song are there out there stored on how many servers and how many backup servers and how many backup backup
up servers, and how often are they being updated and so forth, and where in the world are we putting them? The colder parts of the world? Because it's nice and cool, it costs less to cool them. Great idea. And so we start to heat those parts of the world up. So there are some problems and challenges there. I think one fix to that, of course, is technology to compute faster and to compute better. But we often create these rebound effects that because we compute faster, we don't... there may come a period where we compute more effectively, but because we compute faster, we actually do more with that faster computing power. So we actually end up not just solving the problem we were hoping to solve, but actually we create more stuff to solve. And I'm not a techno- negative person, but it's just a fact that we are creating bigger and bigger environmental footprints with what we're doing with data, and not only storage and computation of data. Yeah, I often think as well when I see these self-driving cars, how much do they actually take of energy to actually to compute the cameras and the sensors and all the other things to be able to do what a human being can do on a couple of pieces of rye bread? It's quite a lot. So we should have not only Federer and Le Bruni, but also rye bread computing, maybe. That's the comparison unit, right? Because I mean, it's ourselves as humans versus something else. And I'm all for automation. I'm all for many different smarter ways of doing things to a point. And I think we need to ask ourselves where is that point with every application? So basically you're saying also that it's similar to when we built more lanes on our roads, that we just see an increased amount of traffic there. So perhaps it's not just about adding more computers or faster computers. But I mean, your perspective I think also was that perhaps we could also think about how we distribute our services. It's the whole topic of green computing. ICT, information and communication technologies, they can both help sustainability or they can help us, I don't know, get more oil and gas and then impair sustainability. So how do you use it in a way that helps sustainability? And how can you reduce its own resource consumption? You can use digital technologies to optimize the energy grid, for example, and district heating. And you can design new infrastructure and new ways of distributing data and computation to reduce consumption. Here it's very important to use renewables to power data centers, for example, and use their excess heat to heat homes in winter, for example. So I think as engineers there's a lot of room for innovation that helps us use digital technologies in a way that helps sustainability. But here it's very important the role of policymakers. You need policies that pushes innovation towards areas where digital technologies are helping and they are not actually impairing sustainability. Preparing for rapid scaling or not? So I think, Christian, you talked about in Italy that security is something that you need to do early on in the way, but design perhaps. What about scalability? Do you need to think about that when you dream about your MVP also in Italy? I think you should be aware there is an issue and if you get a lot of users then you should have an idea of how you can scale, but you shouldn't over-optimize. You shouldn't from the beginning think about scalability. You shouldn't emulate, like I was saying, what Netflix is doing and what Google is doing. You shouldn't get from the start to use Kubernetes and so on. You should, of course, have a solution that can scale, but be worried about large-scale scalability, let's say, later on as you get more users. And you can also reach the other end of the spectrum. There are companies that have so many users and they're consuming so many cloud resources that they have bills of, I don't know, millions of euros per year. We were discussing before we started about this example of Basecamp from 37signals. It's a productivity suite and they switched to their own data center. Basically, they realized it costs less to just pay Dell to ship a pallet of servers to a data center where they install it and hook it up to the Internet and then they can start their services there in some simple way. And they could reduce their costs by actually managing their own data center. And there's a lot of software and tools that allow you to do that, not at the scale that Google is doing, but at the scale that can serve your users. So that's also something to think about. How can you right-size? How can you pay only for what you use? Cloud computing can be expensive. So just to add on to that, there seems to be a trend that we are accepting new technology more rapidly and kind of like internalizing it more quickly. So if you're looking at some of the bigger companies and how long it took them to get 100 million users, I think I saw some numbers recently where it would take Google Translate about 52 months or several years to get 100 million users. It took ChatGPT two months. And we're seeing that TikTok also a few months to get to that. So while I generally agree with what Paul just said, you need to realize that if you have something that is a brilliant idea, then perhaps you only have like a month or two to upgrade to a more sustainable, in the non-sustainable way, software platform to service all the many customers or users that you might actually get. Yeah, of course, you should dream big. You should dream about becoming ChatGPT that gets 100 million users in a month or so. But that's very unlikely to happen. So you should not over-engineer your solution. That's what I'm saying. You should definitely be aware that scalability is important and have a solution that you can scale up to some degree. But you should not spend all your time in worrying about being swamped with a billion of users, because that's unlikely to happen. Of course, it can happen. And of course, you should consider in your design that you need to scale. And by using cloud computing, you can scale. But at the same time, that should not be your primary concern. Your primary concern should be serving the users, making sure you address their needs, creating value for them, making sure you protect their data and privacy. And then using something that is, let's say, state-of-the-art and that allows you to scale, but not go beyond that, not think about being swamped by a billion users the day you open your service. Even ChatGPT had some issues in the beginning, right, of scalability. And Microsoft helped them to scale. They signed a contract, 10 billion US dollars. How much was it? That's a good start. If you become so successful, don't worry, Microsoft will knock on your door and help you scale. So basically, you're saying that we should, you know, prepare for what we think is the most likely scenario, but then be ready for when the best thing happens. Is hardware a ball and chain when it comes to scaling? I maybe ask a question because I come from the product world, the physical product world. And there we have different, let's say, different advice to first students here, but also to industry about where to, what different strategies to have at the different stages of scaling a product-based business or a product in itself. In the software world and the data world, do you have any particular strategies for what types of scalability, affordability you put in at a cold start versus when it gets a good rematch to the inflection point where it goes crazy, but also from a security perspective, are there things that you say you should design security in from the start? And then you're saying, well, that you should not design, over-design things, but are there some good practices in different stages of your business? It's basically another way of maybe thinking about this. Is there continuum or do you need to sort of plan for some transitions between the different stages there? From a data perspective, it's easy, right? You just have a bigger server. Yeah, I guess. But I think also the big companies, they're always looking for data source n plus one, right? Yeah. And they're always looking for data source n plus one, right? And also the big companies, they're always looking for data source n plus one, right? What's the next thing I can collect on you that will give me value down the line? They're really seeing this as a business model, if you think of Google, et cetera, right? It's really our data that's their value. And then I think they have thought about this for sure, right? And also how can you then... So one thing is just storing the data. Another thing is making it accessible for the digital products so you can actually compute something on it and bring that value back to the consumer. Yeah.
From a security perspective, Christian, if you look at these different stages, what would be the most important things? Maybe Paul also teached you about what are the three important things that we should consider when we design things. When you're on the scalability journey, then as systems scale, there are going to be more access points, so there are going to be more people engaging with your system from all locations around the world, so you need to have a local presence in more locations, which means that the attack surface of your system becomes much larger. And that's something that you need to consider. And then also, once your system grows, then it typically also becomes more complex. And so when you build your system, try to engineer it in such a way that with scalability you don't get added complexity, which means that relying on technologies where essentially you can get somebody else to manage the scaling for you, so that you don't need to introduce new levels or new hierarchies of services and caches around the world, but to see if you can't just have the same uniform service from your application point of view, regardless of where you are, and then pay somebody to manage the data centers or manage the data centers yourself, as Paul also suggested, but in a way that's uniform around the world and you don't get added application complexity, because otherwise it's going to be very, very difficult to manage. So from your perspective, I mean, it could also be done as a regional, geographical start-up time. You start with Europe, and once you fix that, then you can move to other parts of the world, for instance. And that's not unusual that people are trying to get to the local market first, maybe not so much in Denmark, because the local market is not really worth targeting alone. But generally, I mean, you will see a lot of things that are popular in one country, and then suddenly it kind of like spreads around to more countries. I don't think that's unusual. Although there are some cases, I guess, like we had MobilePay is one that started here in Scandinavia, at least, and there may be also other services that are originating here from Denmark that have been starting out as small ones that are growing, I guess. So that could also be a strategy. It happens. I also see it with, now I'm dating myself here, Skype, which used to be the WhatsApp of the noughties. And that was also kind of like a small app in Estonia and then Scandinavia that kind of like spread around the world. And they also got bought by Microsoft at some point. But you're touching on something. You talk about products. Those are physical. We talk about virtual world. I think a lot of innovation can come from having physical products, from having hardware. But hardware startups are extremely difficult to work with. Then you cannot just, you know, scale it in a cloud. Scalability there is about logistics. You have to be Tim Cook and you have to have Apple money to be able to design a good product, a physical product. If you want to design a wearable, for example, probably the solution you can get from suppliers is not the same that somebody like Apple can get because they can design their own production processes. They can buy the whole factory and invest hundreds of millions of dollars just to figure out how to integrate something that you can never dream about integrating. There I am excited about hardware startups and you should not be afraid of working on that. But scalability there is something else. Scalability there is about supply chains and about making sure you can source it from the right places. And then it's an issue of supply chain risk and how do you manage that. It can introduce security risks also if a supplier maybe puts a backdoor in your product. It's a whole different host of topics. But because products and hardware are so difficult, you have these stages on how you scale. Whereas with software, people perceive it as, OK, let me from the beginning make it extremely scalable. And we don't often think about stages. That's my impression. Yeah. So there might be stages there still, like you pointed out. But you put your software on the server somewhere and then it's just a question of whether you can handle the download charges and process the credit card transactions, right? And then you're done. Exactly. But I can attest to, I mean, I'm a bit involved in a startup that is doing a hardware device and that needs medical approval. And doing that in this time where you have supply chain issues is not making things simpler. So you're longing for the maybe less complex software world. But just to put a little bit of a silver lining on the cloud that Paul just introduced, then when Apple created the iPod, it was basically a bankrupt company. So when Steve Jobs came back, that was essentially, he took over a company that was more or less bankrupt. And then with a few innovative products, he actually turned the whole Apple company around 25 years ago. So if you have a good hardware idea, don't despair, but think that you can do stuff. But I think that's actually a good point also, Christian. I think because the iPod was, of course, a device that could be sold and create value for the users. And there's a lot of interesting sort of points about how that was designed. But I guess that we're not using our iPods that much any longer, if we still have them. We've moved to sort of more cloud-based solution. But I think what has happened there was that because Apple delivered the iPod, they could also learn from our behaviors, what we downloaded. So even if it was like distributed computing, we would have an access device that contained the data that allowed Apple also to build information about how we were using data, right? All of these big companies are doing that a lot, learning from the data. It may not be just creating value, but just collecting them and then seeing, OK, what are the behaviors? Where are we going? What might be new market trends? Or how can you meet some of the, yeah, sort of maybe even unspoken user demands, right? Yeah. How can that benefit the users at the end of the day, of course? So at least I think that's an important perspective also. How do we ethically and in secure ways actually make sure our services benefit the users? At the end of the day, that's why we buy systems, I guess. Absolutely. And I think there's always a fine line between taking and using data to make service and value offerings better, and at the same time, going too close to the user and the user's data. So I think it's for sure an ethical discussion, and I'm intrigued to know how much that is actually being taught here at DTU about the ethics of data and the ethics of computing. In an innovation perspective, I think we need to know, and our future engineers need to know, where the lines are, at least to ask the question at the right time in the development program, the innovation process, and how close can we actually go there? And there's frameworks, and there's laws, and there's regulations that naturally put those types of frameworks into place. There's always new cases that we should have some form of a mindset of being able to weigh up value versus how close it's too close. Yeah. And I mean, maybe even in this time of chat GPT and large language models and transformers and diffusion networks and so on, that's essentially mining all of the data out there, everything that we thought about or wrote about or whatever. And of course, that brings a lot of other perspectives into this, that now we are maybe migrating to a slightly new set of challenges that we haven't met before, and we still need to apply some of the same methodologies for that. So maybe to sum up some of these discussion points, I think it's been super interesting to hear your perspectives on this, or you should have one piece of advice to give to somebody that is dreaming about starting the new chat GPT, or maybe a little bit less. We can also do with 100 million users in three months, that's also okay. So what would be sort of the key advice? What is the key takeaway that we should think about now? So do you want to start, Paul, about your perspective on that? We've been talking about many different topics and perspectives, and somebody that would like to start an innovative product or service may be worried about all of this complexity. My advice would be, don't worry, try to ignore it as long as you can, because that's how you survive. If the first thing you think about when you want to design something is GDPR, then you'll probably just be bogged by all of this complexity that we have, especially in Europe. My advice is not necessarily that you should move to the US or to the UK to escape, I don't know, regulatory frameworks, but at least just serve your users, figure out what adds value to them, and make sure that you do it in a way that has integrity and protects their values. And then, as things progress, you will naturally be facing all of these things that we're discussing, and then come back to the podcast and figure out what's relevant. Thanks. Karsten, your perspective?
Yeah, I'm not quite sure that I agree with what was just being said because I think if you ignore security and especially if you ignore things like GDPR and collect data for secondary use, for instance, then the entire business model can be invalidated by regulation. And so you'll just be a failed company and you will not provide value to your users, you'll not provide value to your investors or to anybody essentially. So I think it's important to understand these things and then to think in security from the beginning. So perhaps you need to think of your product as is this something that I would use even if my worst enemy was actually the supplier of the product or the service. And if you can agree to that, then you're probably okay. Nina? Well, I also think that the number one is understand your user. I think it's very difficult to bring any kind of value if you don't understand the user. And then, yeah, yes, I wouldn't ignore anything. I think this would be kind of if I start up a company, it would be the values of the company also to do something good, to be ethical, to be fair, et cetera. So it kind of, you would think about that all the time. But just because, yeah, I mean, it's, and then of course there are some decisions that you might push, like first you need to check, like, okay, can I even bring that value to the user? Can I make this technical stuff work, et cetera? And then you might want to think about the details of all of the other stuff, right? So you kind of do maybe prototyping and then prototyping, and then, I mean, the usual innovation pipeline, right? But yeah. Tim? Yeah, again, I think from my perspective as a product developer, innovation process person from more from the physical world, I bring this mindset with me that there must be stages, there must be developments over time of how to plan new startups, new activities, new value propositions. And I've not thought about it in the data world until today, but it's not quite true. I have a little bit of experience from a couple of platforms we've created from some of our research which are based on data and user data. And we've tried in one of them to think, how do we, from a scalability perspective, provide the right advice to the user when there's a couple of hundreds of users? And then what do we do when there's a couple of thousands of users? And what do we hopefully do if we hopefully get hundreds of thousands of users? And this particular project is in a stage where we have a few thousand users. So we're going from relatively static recommendations to doing cluster-based recommendations. So hopefully then we can do some machine learning, how can we sort of do that? So I think thinking those stages from a data perspective, I would say there must be a way of framing that somehow. I've not thought about the security scalability before this conversation here. I've always thought, well, we should make it as secure as possible because we're taking companies and people's data and we're living up to all the GDR and so forth. But how to design that in from the start, I think is a really important concern. At the same time, it's about getting bogged down and sitting, as Paul says, in the corner and thinking, my God, this is too complex for everyone to get started. That's the product development perspective. From the sustainability perspective, I think we need and must do things smarter to be able to somehow see if we can decouple the knowledge we create from the environmental footprint we're also creating. And that is an enormous issue. I just needed to get that word. That's important. That's also important. So basically, maybe to sum it up, be an optimist, Paul, but don't be ignorant on what you're doing. Care about your users and the value you create for them and continuously reflect on your journey and be smart. So thank you very much for coming today to participate in the podcast. I think it's been very interesting to hear your perspectives and I think it's good that we sometimes don't bring the same perspective because the world is complex and we're engineers. We want to engineer things, but we need to understand the complexity.
