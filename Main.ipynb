{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\agish\\appdata\\roaming\\python\\python311\\site-packages (1.55.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\agish\\appdata\\roaming\\python\\python311\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\agish\\appdata\\roaming\\python\\python311\\site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.10.12)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\agish\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\agish\\appdata\\roaming\\python\\python311\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\agish\\appdata\\roaming\\python\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install moviepy\n",
    "# %pip install openai pydub\n",
    "# %pip install python-dotenv\n",
    "%pip install --upgrade openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting MP4s to MP3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 files in 'C:\\Users\\agish\\Documents\\GitHub\\WhisperUse\\Input'.\n",
      "[1] Skipping (already exists): DINK1.1 Intro (Original).mp4\n",
      "[2] Skipping (already exists): DINK1.2.mp4\n",
      "[3] Skipping (already exists): DINK1.3.mp3\n",
      "[4] Skipping (already exists): DINK2.1 introvideo_final (Original).mp4\n",
      "[5] Skipping (already exists): DINK2.2 per_-_clarification_of_concepts_final (Original).mp4\n",
      "[6] Skipping (already exists): DINK2.3 case__mobilepay_final (Original).mp4\n",
      "[7] Skipping (already exists): DINK2.4 veo_case_final (Original).mp4\n",
      "[8] Skipping (already exists): DINK2.5 corti_case_final (Original).mp4\n",
      "[9] Skipping (already exists): DINK2.6 paul_pop_-_ressource_management_final (Original).mp4\n",
      "[10] Skipping (already exists): DINK2.7 christian_d._jensen_final (Original).mp4\n",
      "[11] Skipping (already exists): DINK2.8 podcast final.mp3\n",
      "Processing completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# Add FFmpeg to PATH if needed\n",
    "path = r'C:\\Users\\agish\\AppData\\Local\\Microsoft\\WinGet\\Packages\\Gyan.FFmpeg.Essentials_Microsoft.Winget.Source_8wekyb3d8bbwe\\ffmpeg-7.1-essentials_build\\bin'\n",
    "if not shutil.which(\"ffmpeg\"):\n",
    "    os.environ[\"PATH\"] += os.pathsep + path\n",
    "\n",
    "# Function to convert MP4 to MP3 using FFmpeg\n",
    "def convert_mp4_to_mp3_ffmpeg(input_file, output_file):\n",
    "    \"\"\"Convert an MP4 file to MP3 using FFmpeg.\"\"\"\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", input_file,\n",
    "        \"-q:a\", \"0\",  # Best quality audio\n",
    "        \"-map\", \"a\",  # Extract only the audio stream\n",
    "        output_file,\n",
    "    ]\n",
    "    subprocess.run(command, check=True)\n",
    "\n",
    "# Process all files in the input folder\n",
    "def process_files(input_folder, output_folder):\n",
    "    \"\"\"Convert MP4 files to MP3 and copy existing MP3 files.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    files = os.listdir(input_folder)\n",
    "    print(f\"Found {len(files)} files in '{input_folder}'.\")\n",
    "\n",
    "    for i, file_name in enumerate(files, start=1):\n",
    "        input_path = os.path.join(input_folder, file_name)\n",
    "        if not os.path.isfile(input_path):\n",
    "            continue  # Skip directories or invalid files\n",
    "\n",
    "        # Define the output file path\n",
    "        output_file = os.path.join(output_folder, os.path.splitext(file_name)[0] + \".mp3\")\n",
    "\n",
    "        # Skip if the output file already exists\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"[{i}] Skipping (already exists): {file_name}\")\n",
    "            continue\n",
    "\n",
    "        if file_name.lower().endswith(\".mp3\"):\n",
    "            print(f\"[{i}] Copying MP3: {file_name}\")\n",
    "            shutil.copy(input_path, output_file)\n",
    "        elif file_name.lower().endswith(\".mp4\"):\n",
    "            print(f\"[{i}] Converting MP4 to MP3: {file_name}\")\n",
    "            try:\n",
    "                convert_mp4_to_mp3_ffmpeg(input_path, output_file)\n",
    "                print(f\"[{i}] Converted and saved to: {output_file}\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"[{i}] Failed to convert {file_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"[{i}] Skipping unsupported file: {file_name}\")\n",
    "\n",
    "    print(\"Processing completed!\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = r\"C:\\Users\\agish\\Documents\\GitHub\\WhisperUse\\Input\"\n",
    "output_folder = r\"C:\\Users\\agish\\Documents\\GitHub\\WhisperUse\\Output\"\n",
    "process_files(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_FILE_SIZE_MB = 25\n",
    "MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_MB * 1024 * 1024\n",
    "CHUNK_DURATION_MS = 10 * 60 * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "def split_audio(file_path, output_folder):\n",
    "    \"\"\"Split audio file into chunks of ~25MB.\"\"\"\n",
    "    audio = AudioSegment.from_file(file_path)\n",
    "    total_duration = len(audio)\n",
    "    chunks = []\n",
    "\n",
    "    for start in range(0, total_duration, CHUNK_DURATION_MS):\n",
    "        chunk_name = f\"{os.path.splitext(os.path.basename(file_path))[0]}_chunk_{start // CHUNK_DURATION_MS}.mp3\"\n",
    "        chunk_path = os.path.join(output_folder, chunk_name)\n",
    "\n",
    "        if os.path.exists(chunk_path):  # Avoid re-splitting\n",
    "            print(f\"Chunk already exists: {chunk_name}\")\n",
    "            chunks.append(chunk_path)\n",
    "        else:\n",
    "            chunk = audio[start:start + CHUNK_DURATION_MS]\n",
    "            chunk.export(chunk_path, format=\"mp3\")\n",
    "            chunks.append(chunk_path)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    \"\"\"Transcribe audio using OpenAI API.\"\"\"\n",
    "    url = \"https://api.openai.com/v1/audio/transcriptions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {openai.api_key}\"}\n",
    "    files = {\n",
    "        \"file\": (os.path.basename(file_path), open(file_path, \"rb\")),\n",
    "        \"model\": (None, \"whisper-1\"),\n",
    "        \"language\": (None, \"en\"),\n",
    "    }\n",
    "\n",
    "    retry_count = 0\n",
    "    max_retries = 3\n",
    "\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            response = requests.post(url, headers=headers, files=files)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get(\"text\", \"\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if response.status_code == 429:\n",
    "                retry_count += 1\n",
    "                print(f\"429 error: Too many requests. Waiting for 1 minute before retrying...\")\n",
    "                time.sleep(60)  # Wait 1 minute\n",
    "            else:\n",
    "                print(f\"Error with API request for {file_path}: {e}\")\n",
    "                break\n",
    "\n",
    "    return \"\"  # Return empty transcript if retries are exhausted\n",
    "\n",
    "\n",
    "def process_folder(input_folder, output_folder):\n",
    "    \"\"\"Process MP3 files in input folder and save transcriptions.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith(\".mp3\"):\n",
    "            input_file_path = os.path.join(input_folder, file_name)\n",
    "            output_file_name = os.path.splitext(file_name)[0] + \".txt\"\n",
    "            output_file_path = os.path.join(output_folder, output_file_name)\n",
    "\n",
    "            # Skip already processed files\n",
    "            if os.path.exists(output_file_path):\n",
    "                print(f\"Skipping {file_name} (transcription already exists).\")\n",
    "                continue\n",
    "\n",
    "            # Handle large files and check for existing chunks\n",
    "            file_size = os.path.getsize(input_file_path)\n",
    "            if file_size > MAX_FILE_SIZE_BYTES:\n",
    "                print(f\"Splitting large file: {file_name}\")\n",
    "                chunks = split_audio(input_file_path, output_folder)\n",
    "            else:\n",
    "                chunks = [input_file_path]\n",
    "\n",
    "            # Transcribe and combine results\n",
    "            transcript = \"\"\n",
    "            for chunk in chunks:\n",
    "                print(f\"Transcribing {chunk}...\")\n",
    "                chunk_transcript = transcribe_audio(chunk)\n",
    "                if chunk_transcript:\n",
    "                    transcript += chunk_transcript + \"\\n\"\n",
    "\n",
    "            # Save transcript if non-empty\n",
    "            if transcript.strip():\n",
    "                with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "                    output_file.write(transcript)\n",
    "                print(f\"Transcription completed for {file_name}.\")\n",
    "            else:\n",
    "                print(f\"No transcription generated for {file_name}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping DINK1.1 Intro (Original).mp3 (transcription already exists).\n",
      "Skipping DINK1.2.mp3 (transcription already exists).\n",
      "Skipping DINK1.3.mp3 (transcription already exists).\n",
      "Skipping DINK2.1 introvideo_final (Original).mp3 (transcription already exists).\n",
      "Transcribing Output\\DINK2.2 per_-_clarification_of_concepts_final (Original).mp3...\n",
      "Transcription completed for DINK2.2 per_-_clarification_of_concepts_final (Original).mp3.\n",
      "Skipping DINK2.3 case__mobilepay_final (Original).mp3 (transcription already exists).\n",
      "Skipping DINK2.4 veo_case_final (Original).mp3 (transcription already exists).\n",
      "Skipping DINK2.5 corti_case_final (Original).mp3 (transcription already exists).\n",
      "Skipping DINK2.6 paul_pop_-_ressource_management_final (Original).mp3 (transcription already exists).\n",
      "Skipping DINK2.7 christian_d._jensen_final (Original).mp3 (transcription already exists).\n",
      "Skipping DINK2.8 podcast final.mp3 (transcription already exists).\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "input_folder = \"Output\"\n",
    "output_folder = \"Transcripts\"\n",
    "process_folder(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Text files have been copied from 'Transcripts' to 'Transcripts_Cleaned'.\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define input and output folder paths\n",
    "output_folder = \"Transcripts\"\n",
    "cleaned_folder = \"Transcripts_Cleaned\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(cleaned_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through files in the output folder\n",
    "for filename in os.listdir(output_folder):\n",
    "    if filename.endswith(\".txt\"):  # Check for text files\n",
    "        source_path = os.path.join(output_folder, filename)\n",
    "        destination_path = os.path.join(cleaned_folder, filename)\n",
    "        shutil.copy(source_path, destination_path)  # Copy file to cleaned folder\n",
    "\n",
    "# Confirm action completed\n",
    "f\"Text files have been copied from '{output_folder}' to '{cleaned_folder}'.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files combined successfully into combined_texts.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def combine_text_files(input_directory, output_file):\n",
    "    \"\"\"\n",
    "    Combines all text files in a directory into a single text file.\n",
    "\n",
    "    Parameters:\n",
    "        input_directory (str): The directory containing the text files to combine.\n",
    "        output_file (str): The path to the output text file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "            for filename in os.listdir(input_directory):\n",
    "                if filename.endswith(\".txt\"):\n",
    "                    file_path = os.path.join(input_directory, filename)\n",
    "                    with open(file_path, 'r', encoding='utf-8') as infile:\n",
    "                        outfile.write(f\"--- Start of {filename} ---\\n\\n\")\n",
    "                        outfile.write(infile.read())\n",
    "                        outfile.write(f\"\\n\\n--- End of {filename} ---\\n\\n\")\n",
    "        print(f\"All files combined successfully into {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Customize these variables\n",
    "input_directory = \"Transcripts_Cleaned\"  # Replace with the directory containing text files\n",
    "output_file = \"combined_texts.txt\"         # Replace with your desired output file name\n",
    "\n",
    "# Call the function\n",
    "combine_text_files(input_directory, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
